PROMPTS = {
  "ABAP Dictionary": (
        "Analyze SAP Dictionary Display Table screenshot and extract core technical structure.\n\n"
        
        "Output Requirements:\n"
        "{\n"
        "  \"Fields\": [\n"
        "    {\n"
        "      \"FieldName\": \"normalized_name\",\n"
        "      \"DataType\": \"DATA_TYPE\",\n"
        "      \"Length\": number\n"
        "    },\n"
        "    ...\n"
        "  ]\n"
        "}\n\n"
        
        "Field Processing Rules:\n"
        "1. Name Normalization:\n"
        "   - Convert all to lowercase\n"
        "   - 'to' → 'date to' (e.g., 'dateto' → 'date to')\n"
        "   - 'from' → 'date from' (e.g., 'datefrom' → 'date from')\n"
        "   - 'txt' → 'length of text' (e.g., 'txtlg' → 'length of text')\n"
        "   - 'lang' → 'langu'\n\n"
        
        "2. Field Exclusion:\n"
        "   - Remove fields containing '/BIC/'\n"
        "   - Remove personal identifiers\n"
        "   - Remove descriptive fields (Short Description, Kurzbeschreibung, etc.)\n\n"
        
        "3. Technical Requirements:\n"
        "   - Include only: FieldName, DataType, Length\n"
        "   - Maintain original data types (CHAR, DATS, etc.)\n"
        "   - Keep original length values\n"
        "   - Output must be system-agnostic and reusable\n\n"
        
        "Example Output:\n"
        "{\n"
        "  \"Fields\": [\n"
        "    {\"FieldName\": \"date from\", \"DataType\": \"DATS\", \"Length\": 8},\n"
        "    {\"FieldName\": \"length of text\", \"DataType\": \"CHAR\", \"Length\": 40}\n"
        "  ]\n"
        "}"
    ),
    "BW4Cockpit (Stammdaten)": "From the provided SAP table screenshot, extract only structural metadata in JSON format:\n\n{\n  \"CleanedColumns\": [\"Cleaned\", \"column\", \"names\"],\n  \"HasLongTextColumn\": true/false,\n  \"LongTextConsistentStructure\": true/false or null,\n  \"InvalidLongTextValues\": [\"List of incorrect entries\"]\n}\n\nInstructions:\n- Extract and clean column names by removing any student- or object-specific suffixes (e.g., 'Semesterende TE8 018' → 'Semester'). - Replace entire name if it contains:\\n     - 'to' → Date to\\n     - 'from' → Date from\\n     - 'long' → Long text\\n     - 'shot' → Short text\\n - 'medium' → Medium text\\n - If it just contains 'date' -> 'Date' \\n \n- Return cleaned column names in 'CleanedColumns'.\n- Check whether a column named 'Long Text' exists:\n   - If yes, set 'HasLongTextColumn': true\n   - If no, set 'HasLongTextColumn': false, 'LongTextConsistentStructure': null, 'InvalidLongTextValues': []\n\n If 'HasLongTextColumn': true and  if there is a row, which contains 'BAU' for Example 'BAU - Bauwesen (Gi)' then set 'LongTextConsistentStructure': true.\n- Otherwise, set it to false and write 'Bauwesen(GI)' in 'InvalidLongTextValues'.\n\nReturn ONLY the metadata JSON. Do NOT extract or return full table data.",
  "Data Source": (
        "Analyze a DataSource definition screenshot in SAP BW (Eclipse) and extract these 4 metadata fields:\n\n"
        "1. 'Zu ignorierende Kopfzeilen' (number of header rows to ignore)\n"
        "2. 'Datenseparator' (field separator character presence)\n"
        "3. 'Escape-Zeichen' (escape character presence)\n"
        "4. 'Zahlenformat festlegen' checkbox status\n\n"
        "Output format (strict JSON only):\n"
        "{\n"
        "  \"IgnoredHeaderRows\": number | null,\n"
        "  \"FieldSeparatorSet\": true | false,\n"
        "  \"EscapeCharacterSet\": true | false,\n"
        "  \"ZahlenformatFestlegen\": true | false\n"
        "}\n\n"
        "Rules:\n"
        "- For header rows: Return null if field is empty\n"
        "- For separators/escape: true if any visible character exists\n"
        "- For checkbox: true only if visibly checked (✓)\n"
        "- Exclude all other information (paths, technical names, etc.)\n"
        "- No additional comments or explanations"
    ),
  "Datenvorschau": (
        "Analyze SAP BW4/HANA data preview screenshot and extract structured data based on table type:\n\n"
        
        "1. For 'Datenvorschau für DataSource' (or 'DataSource Preview') tables:\n"
        "   - Extract ONLY column headers\n"
        "   - Return as JSON list under 'Columns' key\n"
        "   - Example: {'Columns': ['Header1', 'Header2', ...]}\n\n"
        
        "2. For 'BW Reporting Vorschau' (or 'BW Reporting Preview') tables:\n"
        "   - Extract BOTH column headers AND last row values\n"
        "   - Return as JSON object with headers as keys and last row as values\n"
        "   - Example: {'Header1': 'Value1', 'Header2': 'Value2', ...}\n\n"
        
        "Processing Rules:\n"
        "• Determine table type by its label before extraction\n"
        "• For reporting previews, ONLY use the last row (totals row)\n"
        "• Exclude all other interface elements and metadata\n"
        "• Return empty object {} if no recognized table found\n\n"
        
        "Output Requirements:\n"
        "- Strict JSON format only\n"
        "- No additional explanations\n"
        "- Case-sensitive headers\n"
        "- Ignore non-data UI elements"
    ),

    "Bewegungsdaten": (
        "Analyze structured text data file image and extract metadata with these rules:\n\n"

        "1. DELIMITER DETECTION:\n"
        "   - Identify the primary column separator character\n"
        "   - Common delimiters: ; , | # TAB\n"
        "   - Must appear consistently in first 5 rows\n\n"

        "2. DATA EXTRACTION:\n"
        "   a) First Data Row:\n"
        "      - Extract first complete non-header row\n"
        "      - Split using detected delimiter\n"
        "      - Output as string array under 'FirstRow'\n"
        "   b) Column Count:\n"
        "      - Derived from 'FirstRow' array length\n\n"

        "3. HEADER DETECTION:\n"
        "   - If first row appears to contain column headers:\n"
        "     * Extract header names\n"
        "     * Output as string array under 'Columns'\n"
        "   - Else: Set 'Columns': null\n\n"

        "OUTPUT FORMAT (strict JSON):\n"
        "{\n"
        "  \"ColumnDelimiter\": \"character\",\n"
        "  \"FirstRow\": [\"value1\", \"value2\", ...],\n"
        "  \"ColumnCount\": number,\n"
        "  \"Columns\": [\"header1\", \"header2\", ...] | null\n"
        "}\n\n"

        "VALIDATION RULES:\n"
        "- Delimiter must be non-alphanumeric\n"
        "- Skip empty/comment rows (starting with # or //)\n"
        "- Trim whitespace from all values\n"
        "- Return null for Columns if headers not detectable\n\n"

        "EXAMPLE OUTPUTS:\n"
        "1. With headers:\n"
        "{\n"
        "  \"ColumnDelimiter\": \";\",\n"
        "  \"FirstRow\": [\"123\", \"2023-01-01\", \"Active\"],\n"
        "  \"ColumnCount\": 3,\n"
        "  \"Columns\": [\"ID\", \"Date\", \"Status\"]\n"
        "}\n\n"
        "2. Without headers:\n"
        "{\n"
        "  \"ColumnDelimiter\": \",\",\n"
        "  \"FirstRow\": [\"A1\", \"B2\", \"C3\", \"D4\"],\n"
        "  \"ColumnCount\": 4,\n"
        "  \"Columns\": null\n"
        "}"
    ),
    "Transformation": (
        "Analyze SAP BW Transformation screenshot. Extract field mappings between Source and Target. Note. The connections between the Source and Target could intersect each other. "
        "following these rules:\n"
        "1. ONLY use visibly connected fields (follow connector lines)\n"
        "2. REMOVE all technical identifiers (like TE007, TE 007 etc.)\n"
        "3. Ignore fields that contain any of the following substrings (in either language):'hochschul', 'zeit', 'ort', 'daten', 'graphie'"
        "4. NORMALIZE names of Source and Target if they contain the following Substrings by applying FIRST matching rule:\n"
        "   'bereich' or 'depart'→'Fachbereich', 'bachelor'→'Bachelorarbeiten'\n"
        "   'promo'→'Promotionen', 'studier'→'Studierenden'\n"
        "   'dritt' or 'exter'→'Drittmittel', 'landes'→'Landesmittel'\n"
        "   'semes'→'Semester', 'bund'or 'stat'→'Bundesland'\n"
        "   'base'→'Base Unit of Measure'\n"
        "   'krz'→'kuerzel', 'von' or 'from'→'gueltig von'm 'to' or 'bis' -> 'gueltig bis'\n"
        "   'bez' or 'descri'→'Bezeichnung'\n"
        "   'valid from' = gueltig von, 'valid to'= 'gueltig bis'"
        "5. return OUTPUT  in JSON format (German only):\n"
        "{\n"
        "  \"Mappings\": [\n"
        "  \"TotalMappings\": number\n"
        "    {\"Source\":\"normalized_name_in_source\", \"Target\":\"normalized_name_in_target\"},\n"
        "    ...\n"
        "  ],\n"
        
        "}"

    ),
    "Data Flow Object": (
        "Analyze SAP BW Data Flow Object screenshot in Eclipse. Return:"
        "1. Total count of objects (Objects are rectangles on the white background in the image.)"
        "2. Whether ALL objects are interconnected\n\n"
        "Rules:\n"
        "- Entire system is 'fully connected' if:\n"
        "  There are no isolated objects\n"
        "return Output in JSON format:\n"
        "{\n"
        "  \"TotalObjects\": number,\n"
        "  \"FullyConnected\": true|false\n"
        "}"
    ),
  "DTP": (
        "Analyze DTP (Data Transfer Process) monitor screenshot in SAP BW (Eclipse) and extract:\n"
        "1. All visible data package names\n"
        "2. Their corresponding record counts\n\n"
        
        "Output Format (strict JSON):\n"
        "{\n"
        "  \"DataPackages\": [\n"
        "    {\"Name\": \"package_name\", \"RecordCount\": number},\n"
        "    ...\n"
        "  ]\n"
        "}\n\n"
        
        "Processing Rules:\n"
        "- Extract ONLY from 'Request Processing' section\n"
        "- Include ONLY fully visible rows in the current view\n"
        "- Never infer or summarize hidden/partial data\n"
        "- RecordCount must be numeric (convert from string if needed)\n"
        "- Exclude all other DTP metadata and UI elements\n\n"
        
        "Example Output:\n"
        "{\n"
        "  \"DataPackages\": [\n"
        "    {\"Name\": \"Package_001\", \"RecordCount\": 1250},\n"
        "    {\"Name\": \"Package_002\", \"RecordCount\": 843}\n"
        "  ]\n"
        "}"
    ),

    "Excel": (
        "Analyze Excel screenshot and extract summary data with these exact rules:\n\n"
        
        "1. If BOTH 'Overall Result' COLUMN AND ROW EXIST:\n"
        "   - Extract ONLY intersecting cell values between the column 'Overall Result' and row 'Overall Result'\n"
        "   - Name keys as 'Overall Result_1', 'Overall Result_2',... (left-to-right order)\n"
        "   Example: {\"Overall Result_1\": \"4,500\", \"Overall Result_2\": \"12%\"}\n\n"
        
        "2. If ONLY 'Overall Result' COLUMN EXISTS:\n"
        "   - Use the corresponding ROW name as key name\n"
        "   - Extract the cell value from 'Overall Result' \n"
        "   Example: {\"Region\": \"North\"}\n\n"
        
        "3. If ONLY 'Overall Result' ROW EXISTS:\n"
        "   - Use COLUMN name as key names\n"
        "   - Extract values from 'Overall Result' of the columns\n"
        "   Example: {\"Total Sales\": \"1,234\", \"Profit\": \"567\"}\n\n"
        
        "4. SPECIAL CASES:\n"
        "   - If multiple matches in scenario 2/3, number them sequentially\n"
        "   - Preserve original formatting (treat as strings)\n"
        "   - Return {} if no valid data found\n\n"
        
        "OUTPUT REQUIREMENTS:\n"
        "- Strict JSON format only\n"
        "- No technical metadata\n"
        "- Empty object if no matches\n"
        "- Numbering starts at 1 for multiple values"
    ),
    "Composite Provider": (
        "Analyze SAP BW Composite Provider screenshot. Extract field mappings between Source and Target "
        "following these rules:\n"
        "1. ONLY use visibly connected fields (follow connector lines)\n"
        "2. REMOVE all technical identifiers (like TE007, TE 007 etc.)\n"
        "3. Ignore fields that contain any of the following substrings (in either language):'hochschul', 'zeit', 'ort', 'daten', 'graphie'"
        "4. NORMALIZE names of Source and Target if they contain the following Substrings by applying FIRST matching rule:\n"
        "   'bereich' or 'depart'→'Fachbereich', 'bachelor'→'Bachelorarbeiten'\n"
        "   'promo'→'Promotionen', 'studier'→'Studierenden'\n"
        "   'dritt' or 'exter'→'Drittmittel', 'landes'→'Landesmittel'\n"
        "   'semes'→'Semester', 'bund'or 'stat'→'Bundesland'\n"
        "   'base'→'Base Unit of Measure'\n"
        "5. return OUTPUT  in JSON format (German only):\n"
        "{\n"
        "  \"Mappings\": [\n"
        "  \"TotalMappings\": number\n"
        "    {\"Source\":\"normalized_name_in_source\", \"Target\":\"normalized_name_in_target\"},\n"
        "    ...\n"
        "  ],\n"
        
        "}"
    ),
    "Query": (
        "Analyze SAP BW Query definition screenshot in Eclipse and extract:\n\n"
        
        "1. FIELD EXTRACTION:\n"
        "   - From 'Spalten'/'Columns (Kennzahlen)': Visible field labels (user-facing names only)\n"
        "   - From 'Filter: Festwerter': Visible field labels (user-facing names only)\n"
        "   - From 'Filter: Standardwerter': Visible field labels (user-facing names only)\n"
        "   - From 'Zeilen'/'Rows': Visible field labels (user-facing names only)\n"
        "   - From 'Freie Merkmale'/'Free Characteristics': Visible field labels\n"
        "   Processing Rules:\n"
        "   • Remove all technical names (TE-numbers like TE6 017)\n"
        "   • Exclude content in square brackets []\n"
        "   • Keep only plain text labels (e.g., 'Semester', not 'Semester TE8 012')\n\n"
        
        "2. PROPERTIES EXTRACTION:\n"
        "   - 'Beschreibung'/'Description': Only if no TE-numbers present\n"
        "   - 'Anzahl Dezimalstellen'/'Decimal Places': (e.g. '0,000' -> '3', '0,0'-> '1' , ) \n"
        "     • Value if 'Anzeigen'/'Display' section visible\n"
        "     • 'nicht vorhanden' if section not visible\n\n"
        
    
        "3. QUERY NUMBER EXTRACTION:\n"
        "   - From title (e.g., 'Datenblatt-Definition: TE8_012_Q5_HS')\n"
        "   - Extract only Q1-Q5 format\n"
        "   - For malformed versions (e.g., 'Q112' → 'Q1')\n\n"
        
        "OUTPUT FORMAT (strict JSON):\n"
        "{\n"
        "  \"Query\": \"Q1-Q5\",\n"
        "  \"Columns\": [\"label1\", \"label2\", ...],\n"
        "  \"Rows\": [\"label1\", \"label2\", ...],\n"
        "  \"Filter: Festwerter\": [\"label1\", \"label2\", ...],\n"
        "  \"Filter: Standardwerter\": [\"label1\", \"label2\", ...],\n"
        "  \"FreeCharacteristics\": [\"label1\", \"label2\", ...],\n"
        "  \"Description\": \"text\" | null,\n"
        "  \"DecimalPlaces\": \"number\" | \"nicht vorhanden\"\n"
        "}\n\n"
        
        "VALIDATION RULES:\n"
        "- Return null for Description if it contains TE-numbers\n"
        "- Arrays should be empty if no valid fields found\n"
        "- No technical names in output\n"
        "- No explanations or metadata\n\n"
        
        "EXAMPLE OUTPUT:\n"
        "{\n"
        "  \"Query\": \"Q3\",\n"
        "  \"Columns\": [\"Fachbereich\", \"Anzahl Studierende\"],\n"
        "  \"Rows\": [\"Jahr\", \"Semester\"],\n"
        "  \"Filter: Festwerter\": [\"Semester\"\n"
        "  \"Filter: Standardwerter\": [\"Land\"\n"
        "  \"FreeCharacteristics\": [\"Campus\"],\n"
        "  \"Description\": \"Student enrollment statistics\",\n"
        "  \"DecimalPlaces\": \"2\"\n"
        "}"
    ),
    "Data Mart": (
        "Analyze SAP BW DataStore Object (Advanced) screenshot. "
        "Determine ONLY whether the 'DataMart' option is selected in the 'Modellierungseigenschaften' section. "
        "Output format (strict JSON):\n"
        "{\n"
        "  \"DataMartSelected\": true|false\n"
        "}\n\n"
        "Rules:\n"
        "- Return true ONLY if the DataMart radio button or checkbox is visibly selected\n"
        "- Return false if unselected, grayed out, or not present\n"
        "- Output must contain ONLY this boolean value\n"
        "- No additional fields or explanations"
    ),
    "Data Store Object": (
        "Analyze SAP BW DataStore Object (Advanced) screenshot and extract ONLY selected options "
        "from 'Modellierungseigenschaften' section.\n\n"
        
        "Processing Rules:\n"
        "1. Rename selected options as follows:\n"
        "   - Contains 'Staging' → 'Staging-DataStore-Objekt'\n"
        "   - Contains 'Eingangs' or Inbound → 'Nur Eingangs-Queue'\n"
        "2. Automatically consider 'Staging-DataStore-Objekt' selected if 'Nur Eingangs-Queue' is selected\n"
        "3. Ignore unselected/grayed-out options\n"
        "4. Exclude fields containing these substrings:\n"
        "   - 'Hot', 'Cold', 'Warm', 'Objektebene', 'Auf', 'Partitionsebene'\n"
        "5. Never extract technical names or personal identifiers\n\n"
        
        "Output Format (strict JSON):\n"
        "{\n"
        "  \"Staging-DataStore-Objekt\": : true|false\n"
        "  \"Nur Eingangs-Queue\": : true|false\n"
        "  ...\n"
        "}\n\n"
    ),
}

def get_prompt(photo_type: str) -> str:
  print("Vom Benutzer ausgewählter Bildtyp:", photo_type)
  return PROMPTS.get(photo_type, "Bildbeschreibung und Rückgabe von JSON.")

